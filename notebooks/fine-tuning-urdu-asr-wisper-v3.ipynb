{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16db3167",
   "metadata": {},
   "source": [
    "\n",
    "# Fineâ€‘tune WhisperÂ Largeâ€‘v3â€¯Turbo on Urdu CommonÂ VoiceÂ 17.0  \n",
    "\n",
    "This notebook follows the official [Huggingâ€¯Face Whisper fineâ€‘tuning guide](https://huggingface.co/blog/fine-tune-whisper) and adapts it to Urdu.  \n",
    "We will:  \n",
    "\n",
    "1. Install & import dependencies  \n",
    "2. Load the Urdu subset of *CommonÂ VoiceÂ 17.0*  \n",
    "3. Preâ€‘process audio & text with `WhisperProcessor`  \n",
    "4. Fineâ€‘tune **`openai/whisper-large-v3-turbo`** with `Seq2SeqTrainer`  \n",
    "5. Track metrics & checkpoints on the Hub (push_to_hub)  \n",
    "6. Run a quick inference demo  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b8383b-5d3c-49cd-be5b-4f7d198f0c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate evaluate jiwer huggingface_hub soundfile librosa tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cea9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "login(hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872c6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import (\n",
    "    AutoProcessor,                    # replaces WhisperProcessor\n",
    "    AutoModelForSpeechSeq2Seq,        # replaces WhisperForConditionalGeneration\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "from evaluate import load as load_metric\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Unionsses import dataclass\n",
    "from typing import Any, Dict, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b125b1-bbc4-4c56-92a8-305b8712b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac72507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# Configuration â€“ edit as you like\n",
    "# ----------------------------------\n",
    "MODEL_ID = \"openai/whisper-large-v3-turbo\"\n",
    "HF_USERNAME = \"kingabzpro\"  #  <-- CHANGE\n",
    "PUSH_MODEL_ID = f\"{HF_USERNAME}/whisper-large-v3-turbo-urdu\"\n",
    "LANG_ID = \"ur\"\n",
    "MAX_AUDIO_SEC = 30\n",
    "SAMPLING_RATE = 16_000\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551f8316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'sentence'],\n",
      "        num_rows: 5368\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'sentence'],\n",
      "        num_rows: 400\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load Common Voice 17.0 Urdu subset\n",
    "dataset = load_dataset(\n",
    "    \"mozilla-foundation/common_voice_17_0\",\n",
    "    LANG_ID,\n",
    "    split={\"train\": \"train\", \"test\": \"test[:400]\"},\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Remove imports with missing audio\n",
    "dataset = dataset.remove_columns(\n",
    "    [col for col in dataset[\"train\"].column_names if col not in (\"audio\", \"sentence\")]\n",
    ")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0626a6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f964e6589774e88a0444358b07cbb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preâ€‘processing:   0%|          | 0/5368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d5b68e080e4acaa66b958e63832475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preâ€‘processing:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(MODEL_ID, language=\"Urdu\", task=\"transcribe\")\n",
    "\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s\\u0600-\\u06FF]+\", \" \", text)  # keep Urdu chars & digits\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def prepare_example(batch):\n",
    "    # Preâ€‘process text\n",
    "    batch[\"sentence\"] = remove_special_chars(batch[\"sentence\"])\n",
    "\n",
    "    # Resample & load audio to 16â€¯kHz\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = processor.feature_extractor(\n",
    "        audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]\n",
    "    ).input_features[0]\n",
    "    # Tokenise labels\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "\n",
    "# Cast audio & preprocess\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))\n",
    "dataset = dataset.map(\n",
    "    prepare_example,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Preâ€‘processing\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2d0c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    pred_ids = eval_pred.predictions  # already (batch, seq_len)\n",
    "    label_ids = eval_pred.label_ids\n",
    "\n",
    "    # Replace -100 so we can decode the references\n",
    "    label_ids = np.where(\n",
    "        label_ids != -100,\n",
    "        label_ids,\n",
    "        processor.tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b102d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=PUSH_MODEL_ID,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    max_steps=2_000,  # ðŸ”§ adapt or set num_train_epochs\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=200,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=2,\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    report_to=[\"tensorboard\"],  # or \"wandb\" if you prefer\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=PUSH_MODEL_ID,\n",
    "    hub_private_repo=False,\n",
    "    hub_strategy=\"every_save\",  # push checkpoints & metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b30f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    MODEL_ID,\n",
    ")\n",
    "model.config.forced_decoder_ids = None  # disable langâ€‘id tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03b5de2f-dc68-468b-9f84-29da5baaf2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67b05a2d-1778-4e9a-bed4-90e386d83628",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d87727e6-40fb-44e7-993a-be0081425852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 32:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>1.070738</td>\n",
       "      <td>0.662857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.700715</td>\n",
       "      <td>0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.545962</td>\n",
       "      <td>0.426286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.462983</td>\n",
       "      <td>0.382571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.5836709747314454, metrics={'train_runtime': 1926.8107, 'train_samples_per_second': 2.076, 'train_steps_per_second': 1.038, 'total_flos': 6.81980461056e+18, 'train_loss': 0.5836709747314454, 'epoch': 0.7451564828614009})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c0b7ed6-16a0-4d06-9887-1c92b157a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 28 19:52:34 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             68W /  400W |   25175MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b731f001-3214-439e-881d-589456a8ec48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206bbe8ffcef47d1806abdad69e22cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/3.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kingabzpro/whisper-large-v3-turbo-urdu/commit/9f74e922a30cc085570b6b1ccf32ac9ade0e8128', commit_message='End of training', commit_description='', oid='9f74e922a30cc085570b6b1ccf32ac9ade0e8128', pr_url=None, repo_url=RepoUrl('https://huggingface.co/kingabzpro/whisper-large-v3-turbo-urdu', endpoint='https://huggingface.co', repo_type='model', repo_id='kingabzpro/whisper-large-v3-turbo-urdu'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the final artefacts\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5adcdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Ø¨ÛŒÛ Ø²ÙˆÙ‚ Ù†ÛÛŒÚº Ø§Ú¯Ø±Ú†Û’ ÙØ·Ø±Øª\n"
     ]
    }
   ],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "sample = dataset[\"test\"][0]\n",
    "input_features = dataset[\"test\"][0][\"input_features\"]\n",
    "\n",
    "input_features = torch.tensor(input_features).unsqueeze(0).to(model.device)\n",
    "pred_ids = model.generate(input_features)[0]\n",
    "print(\"Prediction:\", processor.decode(pred_ids, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81cb4f7-79f4-4ea8-a5fa-c7c8aac054e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
